{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from datetime import datetime\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features:\n",
      "['mean radius' 'mean texture' 'mean perimeter' 'mean area'\n",
      " 'mean smoothness' 'mean compactness' 'mean concavity'\n",
      " 'mean concave points' 'mean symmetry' 'mean fractal dimension'\n",
      " 'radius error' 'texture error' 'perimeter error' 'area error'\n",
      " 'smoothness error' 'compactness error' 'concavity error'\n",
      " 'concave points error' 'symmetry error' 'fractal dimension error'\n",
      " 'worst radius' 'worst texture' 'worst perimeter' 'worst area'\n",
      " 'worst smoothness' 'worst compactness' 'worst concavity'\n",
      " 'worst concave points' 'worst symmetry' 'worst fractal dimension']\n",
      "\n",
      "Targets:\n",
      "['malignant' 'benign']\n"
     ]
    }
   ],
   "source": [
    "dataset = load_breast_cancer()\n",
    "print(\"Features:\")\n",
    "print(dataset.feature_names)\n",
    "print(\"\\nTargets:\")\n",
    "print(dataset.target_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = dataset.data\n",
    "y = dataset.target\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize features\n",
    "scaler = StandardScaler()\n",
    "x_train = scaler.fit_transform(X_train)\n",
    "x_test  = scaler.fit_transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Try different SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training time: 0:00:00.019290\n",
      "Train accuracy: 1.00\n",
      "Test  accuracy: 0.56\n"
     ]
    }
   ],
   "source": [
    "# Unscaled features are problematic for the rbf kernel\n",
    "model = SVC(kernel = 'rbf', gamma='auto')\n",
    "\n",
    "t0 = datetime.now()\n",
    "model.fit(X_train, y_train)\n",
    "print(f\"Training time: {datetime.now() - t0}\")\n",
    "print(f\"Train accuracy: {model.score(X_train, y_train):.2f}\")\n",
    "print(f\"Test  accuracy: {model.score(X_test, y_test):.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training time: 0:00:00.009964\n",
      "Train accuracy: 0.95\n",
      "Test  accuracy: 0.94\n"
     ]
    }
   ],
   "source": [
    "# The rbf kernel with gamma='scale' deals much better with unscaled features\n",
    "model = SVC(kernel = 'rbf', gamma='scale')\n",
    "\n",
    "t0 = datetime.now()\n",
    "model.fit(X_train, y_train)\n",
    "print(f\"Training time: {datetime.now() - t0}\")\n",
    "print(f\"Train accuracy: {model.score(X_train, y_train):.2f}\")\n",
    "print(f\"Test  accuracy: {model.score(X_test, y_test):.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training time: 0:00:00.006299\n",
      "Train accuracy: 0.99\n",
      "Test  accuracy: 0.96\n"
     ]
    }
   ],
   "source": [
    "# The rbf kernel performs much better with normalised features\n",
    "model = SVC(kernel = 'rbf', gamma='auto')  # same as gamma='scale' with normalised features\n",
    "\n",
    "t0 = datetime.now()\n",
    "model.fit(x_train, y_train)\n",
    "print(f\"Training time: {datetime.now() - t0}\")\n",
    "print(f\"Train accuracy: {model.score(x_train, y_train):.2f}\")\n",
    "print(f\"Test  accuracy: {model.score(x_test, y_test):.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training time: 0:00:00.812120\n",
      "Train accuracy: 0.96\n",
      "Test  accuracy: 0.96\n"
     ]
    }
   ],
   "source": [
    "# The linear model works fine even with unscaled features\n",
    "model = SVC(kernel='linear')\n",
    "\n",
    "t0 = datetime.now()\n",
    "model.fit(X_train, y_train)\n",
    "print(f\"Training time: {datetime.now() - t0}\")\n",
    "print(f\"Train accuracy: {model.score(X_train, y_train):.2f}\")\n",
    "print(f\"Test  accuracy: {model.score(X_test, y_test):.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training time: 0:00:00.005530\n",
      "Train accuracy: 0.99\n",
      "Test  accuracy: 0.96\n"
     ]
    }
   ],
   "source": [
    "# The linear model still performs slightly better with scaled features\n",
    "model = SVC(kernel='linear')\n",
    "\n",
    "t0 = datetime.now()\n",
    "model.fit(x_train, y_train)\n",
    "print(f\"Training time: {datetime.now() - t0}\")\n",
    "print(f\"Train accuracy: {model.score(x_train, y_train):.2f}\")\n",
    "print(f\"Test  accuracy: {model.score(x_test, y_test):.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Better model comparison with cross validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to properly compare different models, we do cross validation with sklearn.model_selection.cross_val_score.\n",
    "\n",
    "Note that data preprocessing steps (such as normalization) must be learnt on the train set, and therefore repeated on each split. To achieve this, we use sklearn.pipeline.make_pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "K = 10  # K-fold cross validation\n",
    "\n",
    "def my_cross_val(model, x, y, cv=K, scale_x=False, **kwargs):\n",
    "    clf = model(**kwargs)\n",
    "    if scale_x: clf = make_pipeline(StandardScaler(), clf)\n",
    "    \n",
    "    scores = cross_val_score(clf, x, y, cv=cv)\n",
    "    print(f\"Accuracy: {scores.mean():0.2f} (+/- {2 * scores.std():0.2f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.63 (+/- 0.01)\n"
     ]
    }
   ],
   "source": [
    "params = {'scale_x': False, 'kernel': 'rbf', 'gamma': 'auto'}\n",
    "my_cross_val(SVC, X, y, **params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.94 (+/- 0.05)\n"
     ]
    }
   ],
   "source": [
    "params = {'scale_x': False, 'kernel': 'rbf', 'gamma': 'scale'}\n",
    "my_cross_val(SVC, X, y, **params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.98 (+/- 0.05)\n"
     ]
    }
   ],
   "source": [
    "params = {'scale_x': True, 'kernel': 'rbf', 'gamma': 'auto'}\n",
    "my_cross_val(SVC, X, y, **params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.95 (+/- 0.04)\n"
     ]
    }
   ],
   "source": [
    "params = {'scale_x': False, 'kernel': 'linear'}\n",
    "my_cross_val(SVC, X, y, **params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.98 (+/- 0.04)\n"
     ]
    }
   ],
   "source": [
    "params = {'scale_x': True, 'kernel': 'linear'}\n",
    "my_cross_val(SVC, X, y, **params)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
