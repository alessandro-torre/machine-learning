{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tutorial: https://towardsdatascience.com/implementing-an-autoencoder-in-tensorflow-2-0-5e86126e9f7\n",
    "GitHub code: https://gist.github.com/AFAgarap/326af55e36be0529c507f1599f88c06e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf  # TF 2.0 required\n",
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(1)\n",
    "tf.random.set_seed(1)\n",
    "\n",
    "learning_rate = 1e-2\n",
    "n_batches = 600\n",
    "epochs = 10\n",
    "\n",
    "# hidden features for compression\n",
    "# We use 2d to be able to plot (or 3d would work too)\n",
    "# TODO: compress less (e.g. 32 features), then use t-SNE to compress to 2d\n",
    "compr_dim = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simple autoencoder with one encoding and one decoding layer.\n",
    "class Encoder(tf.keras.layers.Layer):\n",
    "  def __init__(self, compr_dim):\n",
    "    super(Encoder, self).__init__()\n",
    "    self.hidden_layer = tf.keras.layers.Dense(\n",
    "      units=compr_dim,\n",
    "      activation=tf.nn.relu,\n",
    "      kernel_initializer='he_uniform'\n",
    "    )\n",
    "    self.output_layer = tf.keras.layers.Dense(\n",
    "      units=compr_dim,\n",
    "      activation=tf.nn.relu,\n",
    "      kernel_initializer='he_uniform'\n",
    "    )\n",
    "    \n",
    "  def call(self, input_features):\n",
    "    return self.output_layer(self.hidden_layer(input_features))\n",
    "\n",
    "\n",
    "class Decoder(tf.keras.layers.Layer):\n",
    "  def __init__(self, compr_dim, original_dim):\n",
    "    super(Decoder, self).__init__()\n",
    "    self.hidden_layer = tf.keras.layers.Dense(\n",
    "      units=compr_dim,\n",
    "      activation=tf.nn.relu,\n",
    "      kernel_initializer='he_uniform'\n",
    "    )\n",
    "    self.output_layer = tf.keras.layers.Dense(\n",
    "      units=original_dim,\n",
    "      activation=tf.nn.relu,\n",
    "      kernel_initializer='he_uniform'\n",
    "    )\n",
    "  \n",
    "  def call(self, code):\n",
    "    return self.output_layer(self.hidden_layer(code))\n",
    "\n",
    "\n",
    "\n",
    "class Autoencoder(tf.keras.Model):\n",
    "  def __init__(self, compr_dim, original_dim):\n",
    "    super(Autoencoder, self).__init__()\n",
    "    self.encoder = Encoder(compr_dim=compr_dim)\n",
    "    self.decoder = Decoder(compr_dim=compr_dim, original_dim=original_dim)\n",
    "  \n",
    "  def call(self, input_features):\n",
    "    code = self.encoder(input_features)\n",
    "    reconstructed = self.decoder(code)\n",
    "    return reconstructed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss(model, original):\n",
    "  reconstruction_error = tf.reduce_mean(tf.square(tf.subtract(model(original), original)))\n",
    "  return reconstruction_error\n",
    "\n",
    "\n",
    "# Training function with imperative forward pass.\n",
    "def train(loss, model, opt, original):\n",
    "  with tf.GradientTape() as tape:\n",
    "    gradients = tape.gradient(loss(model, original), model.trainable_variables)\n",
    "    gradient_variables = zip(gradients, model.trainable_variables)\n",
    "    opt.apply_gradients(gradient_variables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the MNIST dataset.\n",
    "# Training labels only used to identify clusters in 2d plot, not for classification (unsupervised learning).\n",
    "(training_features, training_labels), (test_features, _) = tf.keras.datasets.mnist.load_data()\n",
    "n_sample = training_features.shape[0]\n",
    "dim_x = training_features.shape[1]\n",
    "dim_y = training_features.shape[2]\n",
    "original_dim = dim_x * dim_y\n",
    "batch_size   = n_sample // n_batches\n",
    "\n",
    "# Normalize and flatten data.\n",
    "training_features = training_features / np.max(training_features)\n",
    "training_features = training_features.reshape(n_sample, original_dim)\n",
    "training_features = training_features.astype('float32')\n",
    "\n",
    "# Convert to TF input pipeline, batch and shuffle.\n",
    "training_dataset = tf.data.Dataset.from_tensor_slices(training_features)\n",
    "training_dataset = training_dataset.batch(batch_size)\n",
    "training_dataset = training_dataset.shuffle(n_sample)\n",
    "training_dataset = training_dataset.prefetch(batch_size * 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary file for TensorBoard\n",
    "writer = tf.summary.create_file_writer('tb/autoencoder/run1')\n",
    "\n",
    "# Instantiate autoencoder model and optimization function.\n",
    "autoencoder = Autoencoder(compr_dim=compr_dim, original_dim=original_dim)\n",
    "opt = tf.optimizers.Adam(learning_rate=learning_rate)\n",
    "\n",
    "# Training loop\n",
    "with writer.as_default():\n",
    "  with tf.summary.record_if(True):\n",
    "    for epoch in range(epochs):\n",
    "      for step, batch_features in enumerate(training_dataset):\n",
    "        train(loss, autoencoder, opt, batch_features)\n",
    "        loss_values = loss(autoencoder, batch_features)\n",
    "        original = tf.reshape(batch_features, (batch_features.shape[0], dim_x, dim_y, 1))\n",
    "        reconstructed = tf.reshape(autoencoder(tf.constant(batch_features)), (batch_features.shape[0], dim_x, dim_y, 1))\n",
    "        tf.summary.scalar('loss', loss_values, step=step)\n",
    "        tf.summary.image('original', original, max_outputs=10, step=step)\n",
    "        tf.summary.image('reconstructed', reconstructed, max_outputs=10, step=step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: plot 2d compressed images, with label-based coloring (training_labels)\n",
    "compressed = autoencoder.encoder(tf.constant(training_features))\n",
    "# converto numpy array, then plot. or use tfplot:\n",
    "# https://tensorflow-plot.readthedocs.io/en/latest/guide/showcases.html\n",
    "# import tfplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Reusing TensorBoard on port 6006 (pid 4630), started 0:10:30 ago. (Use '!kill 4630' to kill it.)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-d54301bed4d9bf28\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-d54301bed4d9bf28\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          url.port = 6006;\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "  "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%tensorboard --logdir tb/autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
